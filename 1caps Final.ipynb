{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5eb6631-9536-4e9a-8723-54f17c778b4c",
   "metadata": {},
   "source": [
    "# Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9de7845-2099-4679-9433-17739472b2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_1samp\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from statsmodels.stats.weightstats import ztest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, recall_score, f1_score, precision_score,classification_report, calinski_harabasz_score, davies_bouldin_score, silhouette_score\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine, text\n",
    "from statsmodels.stats.weightstats import ztest\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c0402c-26b3-42c5-b5f1-4db6c2addf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Files\n",
    "appearances = pd.read_excel('appearances.xlsx')\n",
    "game_events = pd.read_excel('game_events.xlsx')\n",
    "game_lineups = pd.read_excel('game_lineups.xlsx')\n",
    "games = pd.read_excel('games.xlsx')\n",
    "players = pd.read_excel('players.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269ace86-446f-4219-9213-3019f8d75e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_1 = pd.merge(appearances, players, on='player_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146e8e03-f118-4390-9a69-1f49f0f67467",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_2 = pd.merge(merged_1, games, on='game_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf57f39-5770-42d7-a077-a605488b981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_3 = pd.merge(merged_2, game_lineups, on=['game_id', 'player_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec6214a-bd91-4721-8973-a33bc82b6e5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(merged_3, game_events, on=['game_id', 'player_id'], how='left')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa2ec50-1866-4095-8f38-14eb1efddd15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bb2f0f-8e12-44a0-8040-b5fcc56e020e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dropping Duplicate Columns\n",
    "col_to_drop = ['date_y','player_name_y','competition_id_y','position_y','type_y']\n",
    "merged_df = merged_df.drop(col_to_drop,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2765ff93-bc1d-43b0-987e-c4169c3c2ccb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# just for observation of values of all columns\n",
    "columns = merged_df.columns\n",
    "for i in columns:\n",
    "    print(f' Column {i}')\n",
    "    val = merged_df[i].value_counts()\n",
    "    print(val.head())\n",
    "    print('------------------------------------------------------------ \\n ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15625dd-240e-4b4a-9815-07835701e102",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Null Percent Column wise\n",
    "null_percentage = (merged_df.isnull().mean() * 100).round(2)\n",
    "null_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a970e450-2bca-48af-b8c8-1598f55207a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns having more than 80% Null values\n",
    "cols_to_drop = null_percentage[null_percentage > 80].index.tolist()\n",
    "merged_df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "print(f\"Dropped {len(cols_to_drop)} columns: {cols_to_drop}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9969425f-c410-483b-965f-bae4b6c10441",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Changing game_id and player_id columns to the object (string) type because these are identifiers, not used for mathematical calculations.\n",
    "\n",
    "merged_df['game_id'] = merged_df['game_id'].astype(object)\n",
    "merged_df['player_id'] = merged_df['player_id'].astype(object)\n",
    "merged_df['current_club_id'] = merged_df['current_club_id'].astype(object)\n",
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32387f8d-b7e6-45b7-92a6-9eb944beec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diffrentiating columns\n",
    "numeric_cols = merged_df.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_cols = merged_df.select_dtypes(include=['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43689db9-06e1-4a67-b107-3eefa977eceb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# foot , home club man name , away , refree - mode fill\n",
    "col_mode = ['foot','home_club_manager_name','away_club_manager_name','referee']\n",
    "fill_val = ['right','Mark Hughes','Mark Hughes','Dr. Felix Brych']\n",
    "for i,j in zip(col_mode,fill_val):\n",
    "    merged_df[i] = merged_df[i].fillna(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4925aca-dbe9-4b5e-b901-a66fd857b364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Null Num cols with median\n",
    "for col in numeric_cols:\n",
    "    if merged_df[col].isnull().sum() > 0:\n",
    "        merged_df[col].fillna(merged_df[col].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86786578-9db8-455d-820f-47cfd37fcdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Date Cols with 1900-01-01\n",
    "merged_df['date'].fillna(pd.to_datetime('1900-01-01'), inplace=True)\n",
    "merged_df['contract_expiration_date'].fillna(pd.to_datetime('1900-01-01'), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d3e86d-fc9d-4726-8994-bf16cc6866d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.dropna(subset=['player_id', 'game_id'], inplace=True) \n",
    "# Dropping rows of player_id and Game id which are null because cant fill it with mean, median as they are having unique ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a75b17-b99a-45c1-a5f6-973232907021",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in categorical_cols: # Filling Nulls of Cat Cols with NA\n",
    "    merged_df[i].fillna('NA',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcf2dac-6767-4f9f-94c5-3adb73bf0106",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377cf0a7-f358-4565-9b3d-2777e28d1d45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(numeric_cols), 1, figsize=(7, 3 * len(numeric_cols)))\n",
    "\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    ax[i].boxplot(merged_df[col], vert=False)\n",
    "    ax[i].set_ylabel(col)\n",
    "    ax[i].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979884db-fe3e-4a14-9b37-b55579830ce3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Treating Outliers using Winsorization Techniqe\n",
    "def winsorization(df):\n",
    "    df_c = merged_df.copy()\n",
    "    cols = [\"minutes_played\", \"market_value_in_eur\", \"highest_market_value_in_eur\"]\n",
    "    for col in cols:\n",
    "        # q1 , q3 and iqr\n",
    "        q1 = df_c[col].quantile(0.25)\n",
    "        q3 = df_c[col].quantile(0.75)\n",
    "        iqr = q3-q1\n",
    "        # LF and UF\n",
    "        lf = q1-1.5*iqr\n",
    "        uf = q3+1.5*iqr\n",
    "        # winsorization\n",
    "        df_c.loc[df_c[col]<lf,col] = lf\n",
    "        df_c.loc[df_c[col]>uf,col] = uf\n",
    "    return df_c\n",
    "\n",
    "win_df = winsorization(merged_df)\n",
    "win_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a249a-ba2b-453d-9036-b7b44610206a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# out_trt is the list of trated outliers columns\n",
    "out_trt = [\"minutes_played\", \"market_value_in_eur\", \"highest_market_value_in_eur\"]\n",
    "fig, ax = plt.subplots(len(out_trt), 1, figsize=(7, 3 * len(out_trt)), dpi=95)\n",
    "\n",
    "for i, col in enumerate(out_trt):\n",
    "    ax[i].boxplot(win_df[col].dropna(), vert=False)\n",
    "    ax[i].set_ylabel(col)\n",
    "    ax[i].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2226dbf-d5e5-475e-a025-895ff74124e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31ebe39-952f-474c-9b41-f85d8cb30fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessaey columns - Name,Home club position and away club position , DOB , Description , game event id\n",
    "drop_cols = ['name','home_club_position','away_club_position','date_of_birth','game_event_id','date','agent_name','contract_expiration_date']\n",
    "win_df.drop(columns = drop_cols,inplace = True)\n",
    "win_df[\"goal_per_90\"] = win_df[\"goals\"] / (win_df[\"minutes_played\"] / 90)\n",
    "len(win_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778f9166-687f-464d-a6d2-4461ff76158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying Column Names\n",
    "win_df.columns = ['Appearance Id', 'Game Id', 'Player Id', 'Date', 'Player Name',\n",
    "       'Competition Id', 'Yellow Cards', 'Red Cards', 'Goals', 'Assists',\n",
    "       'Minutes Played', 'Last Season', 'Current Club Id', 'Player Code',\n",
    "       'Country of birth', 'Sub Position', 'Position', 'Prefered Foot',\n",
    "       'Height in cm', 'Market value in eur', 'Highest market value in eur','Season','Round',\n",
    "       'Home_club_goals', 'away_club_goals', 'home_club_manager_name',\n",
    "       'away_club_manager_name', 'Stadium', 'Attendance', 'Referee',\n",
    "       'home_club_name', 'away_club_name', 'Aggregate', 'Competition type','Minute','goal_per_90']\n",
    "win_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8a4442-cc98-47ee-bb73-a1045eb02e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_df.to_csv(\"football_data_merged_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3347818-d7d6-40d0-a13e-309b69dc30d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MySQL without database\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"root\"\n",
    ")\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "# Creating database if it doesn't exist\n",
    "cursor.execute(\"CREATE DATABASE IF NOT EXISTS football\")\n",
    "mydb.close()\n",
    "\n",
    "# Establish SQLAlchemy engine to the database\n",
    "engine = create_engine('mysql+mysqlconnector://root:root@localhost:3306/football')\n",
    "\n",
    "df = win_df  \n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS FinalCleanedData\"))\n",
    "    \n",
    "df.to_sql(name='FinalCleanedData', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Data inserted successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71afa336-97fc-4f21-91b9-41c743e88deb",
   "metadata": {},
   "source": [
    "# Interpretation : Phase 1\n",
    "\n",
    "We started by loading multiple football-related datasets and merging them into one combined dataset for easier analysis.After merging, we checked for\n",
    "missing values and dropped columns with too many missing entries. For the remaining missing data, we filled numeric columns with median values,\n",
    "categorical columns with \"NA\", and dates with a placeholder date. We removed duplicate and unnecessary columns to keep the dataset clean. To handle extreme values, we capped outliers in numeric data. \n",
    "Finally, the cleaned and processed dataset is ready for analysis or modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986ba25a-4fd2-453c-9273-5f82145e6411",
   "metadata": {},
   "source": [
    "# Phase 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed844dda-96a2-4562-8304-6dd227885142",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = win_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c89bd9-a70a-44a3-8660-cc9e3a3aff3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4900114a-7613-4311-91fe-213c07069cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.describe(include = 'object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c301297-f673-4bf6-8436-71f9ca90b697",
   "metadata": {},
   "source": [
    "# CLT - For Goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2807d58-978a-49ed-a2f3-53b8b5a1284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,10))\n",
    "plt.subplot(2,1,1)\n",
    "sns.kdeplot(final_df['Goals'], color='blue', linewidth=2)\n",
    "plt.title('KDE of Original Goals')\n",
    "plt.xlabel('Goals')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "# Central Limit Theorem\n",
    "sample_size = 30\n",
    "num_samples = 1000\n",
    "sample_means = [final_df['Goals'].sample(sample_size, replace=True,random_state=i).mean() for i in range(num_samples)]\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "sns.kdeplot(sample_means, color='red', linewidth=2)\n",
    "plt.title('KDE of Sample Means (CLT)')\n",
    "plt.xlabel('Sample Mean of Goals')\n",
    "plt.ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a910aa85-a97d-4aa9-a17c-f3a36358afd5",
   "metadata": {},
   "source": [
    "# Probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e4d02e-9504-4c9b-b97b-d7b60d424499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of Assisting\n",
    "p_assist = ((final_df['Assists'] > 0).sum() / len(final_df)) * 100\n",
    "\n",
    "# Probability a player neither scores nor assists\n",
    "p_no_goals_no_assist = (((final_df['Goals'] == 0) & (final_df['Assists'] == 0)).sum() / len(final_df)) * 100\n",
    "\n",
    "# Probability a player either scores or assists\n",
    "p_goals_or_assist = (((final_df['Goals'] > 0) | (final_df['Assists'] > 0)).sum() / len(final_df)) * 100\n",
    "\n",
    "# Probability a player assists given they have scored (conditional probability)\n",
    "cond_assist_given_goals = (((final_df['Assists'] > 0) & (final_df['Goals'] > 0)).sum() / (final_df['Goals'] > 0).sum()) * 100\n",
    "\n",
    "# Probability a player scores given they have assisted (conditional probability)\n",
    "cond_goals_given_assist = (((final_df['Goals'] > 0) & (final_df['Assists'] > 0)).sum() / (final_df['Assists'] > 0).sum()) * 100\n",
    "\n",
    "print(\"Probability of Assisting:\", p_assist)\n",
    "print(\"Probability of No Goals and No Assists:\", p_no_goals_no_assist)\n",
    "print(\"Probability of Goals or Assists:\", p_goals_or_assist)\n",
    "print(\"Conditional Probability of Assist Given Goals:\", cond_assist_given_goals)\n",
    "print(\"Conditional Probability of Goals Given Assist:\", cond_goals_given_assist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf0c2f4-dab7-49c7-9792-2419560d4828",
   "metadata": {},
   "source": [
    "# Linear Regression Model for Predicting Goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc93fd4-a7fc-453d-8b82-bd850c19217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Make a copy to avoid changing original data\n",
    "df_copy = final_df.copy()\n",
    "\n",
    "# Encode all categorical (object type) columns\n",
    "label_encoder = LabelEncoder()\n",
    "for col in df_copy.select_dtypes(include=['object', 'category']).columns:\n",
    "    df_copy[col] = label_encoder.fit_transform(df_copy[col].astype(str))\n",
    "\n",
    "# Now, all columns are numeric\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12,8))\n",
    "sns.heatmap(df_copy.corr(), annot=True, cmap='coolwarm', fmt='.2f', ax=ax)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2606c53d-3d26-4ba9-afec-d92e0214577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap\n",
    "num_data = final_df.select_dtypes(include=['number'])\n",
    "fig,ax = plt.subplots(1,1 , figsize = (12,8))\n",
    "ax = sns.heatmap(num_data.corr(),annot = True,cmap='coolwarm',fmt='.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dbf416-6e26-4307-92e1-66d2bd8dbf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['goal_per_90', 'Assists', 'Minutes Played', 'Home_club_goals', 'away_club_goals']\n",
    "X = final_df[features]\n",
    "y = final_df['Goals']\n",
    "\n",
    "# Splitting into train and test set\n",
    "X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "# Build and train model\n",
    "model_goal = LinearRegression()\n",
    "model_goal.fit(X_train_g, y_train_g)\n",
    "# Predict on test data\n",
    "y_pred_g = model_goal.predict(X_test_g)\n",
    "\n",
    "# Evaluate model\n",
    "mae = mean_absolute_error(y_test_g, y_pred_g)\n",
    "mse = mean_squared_error(y_test_g, y_pred_g)\n",
    "RMSE = mean_squared_error(y_test_g,y_pred_g,squared = False)\n",
    "r2 = r2_score(y_test_g, y_pred_g)\n",
    "print(\"Mean Absolute Error (MAE):\", round(mae,2))\n",
    "print(\"Mean Squared Error (MSE):\", round(mse,2))\n",
    "print(\"R2 Score:\", round(r2,2))\n",
    "print(\"RMSE:\", round(RMSE,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc5585a-6814-48d0-867b-eab10a063daf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading Test data to predict with model\n",
    "test_data = pd.read_excel('test data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b91effe-a038-44b1-871e-efbe9907c4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "test_data.rename(columns={\n",
    "    'assists': 'Assists',\n",
    "    'minutes_played': 'Minutes Played',\n",
    "    'home_club_goals': 'Home_club_goals',\n",
    "    'away_club_goals': 'away_club_goals'  \n",
    "}, inplace=True)\n",
    "\n",
    "test_data['goal_per_90'] = test_data['goals'] / test_data['Minutes Played'] * 90\n",
    "X_new_g = test_data[['goal_per_90', 'Assists', 'Minutes Played', 'Home_club_goals', 'away_club_goals']]\n",
    "predicted_goals = model_goal.predict(X_new_g)\n",
    "\n",
    "test_data['predicted_goals'] = predicted_goals\n",
    "predicted_goals_rounded = np.round(predicted_goals).astype(int)\n",
    "predicted_goals_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aecac4-3e53-43ff-ae61-41c367b33622",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_goal = y_test_g - y_pred_g\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(range(len(residuals_goal)), residuals_goal)\n",
    "plt.axhline(0, color='Purple', linestyle='--')\n",
    "plt.title('Residual Plot')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Residual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a430d7-9f5a-490e-b961-b34a7fb7193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Actual vs Predicted Chart\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(y_test_g, y_pred_g)\n",
    "plt.plot([min(y_test_g), max(y_test_g)], [min(y_test_g), max(y_test_g)], color='Purple', linestyle='--')\n",
    "plt.xlabel(\"Actual Goals\")\n",
    "plt.ylabel(\"Predicted Goals\")\n",
    "plt.title(\"Actual vs Predicted Goals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5756d8f4-1e76-48f7-942a-2030a00ef220",
   "metadata": {},
   "source": [
    "# Market Value Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0781d312-d6e4-47f5-bf2f-678454e2405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cols_mv = final_df.select_dtypes(include = ['int32','int64','float64'])\n",
    "cols=model_cols_mv.columns\n",
    "scaler=StandardScaler()\n",
    "df_scaled_mv=scaler.fit_transform(model_cols_mv)\n",
    "df_scaled_mv=pd.DataFrame(df_scaled_mv, columns=cols)\n",
    "df_scaled_mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e12078b-eb81-43b6-86a6-aebe65acd35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap\n",
    "num_data = df_scaled_mv.select_dtypes(include=['number'])\n",
    "fig,ax = plt.subplots(1,1 , figsize = (12,8))\n",
    "ax = sns.heatmap(num_data.corr(),annot = True,cmap='coolwarm',fmt='.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ea5be-18dc-4372-9ba1-fad67e7cb275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using only the relevant columns\n",
    "features = ['Highest market value in eur', 'Season', 'Last Season','Attendance']\n",
    "target = 'Market value in eur'\n",
    "\n",
    "X1 = df_scaled_mv[features]\n",
    "y1 = df_scaled_mv[target]\n",
    "\n",
    "# Train/test split\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=7)\n",
    "\n",
    "# model\n",
    "model_mv = LinearRegression()\n",
    "model_mv.fit(X1_train, y1_train)\n",
    "\n",
    "# Predicting and evaluate performance\n",
    "y1_pred = model_mv.predict(X1_test)\n",
    "r2 = r2_score(y1_test, y1_pred)\n",
    "mse = mean_squared_error(y1_test, y1_pred)\n",
    "mae = mean_absolute_error(y1_test, y1_pred)\n",
    "rmse = mean_squared_error(y1_test, y1_pred , squared =  False)\n",
    "\n",
    "print(\"R2 Score:\", round(r2,2))\n",
    "print(\"Mean Absolute Error (MAE):\", round(mae,2))\n",
    "print(\"Mean Squared Error (MSE):\", round(mse,3))\n",
    "print(\"RMSE :\" ,round(rmse,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7fbece-c595-4b5b-aa12-4f2994718776",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_mv = y1_test - y1_pred\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(range(len(residuals_mv)), residuals_mv, alpha=0.7)\n",
    "plt.axhline(0, color='Purple', linestyle='--')\n",
    "plt.title('Residual Plot')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Residual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1af3bba-d308-488c-901c-d7e7b88b8da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Actual vs Predicted Chart\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(y1_test, y1_pred)\n",
    "plt.plot([min(y1_test), max(y1_test)], [min(y1_test), max(y1_test)], color='Purple', linestyle='--')\n",
    "plt.xlabel(\"Actual Market Value\")\n",
    "plt.ylabel(\"Predicted Market Value\")\n",
    "plt.title(\"Actual vs Predicted Market Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803ba3e1-a086-49e6-a7c5-36efcd2e8782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "test_data.rename(columns={\n",
    "    'season': 'Season',\n",
    "    'highest_market_value_in_eur': 'Highest market value in eur',\n",
    "    'last_season': 'Last Season',\n",
    "    'attendance' : 'Attendance'\n",
    "}, inplace=True)\n",
    "\n",
    "# Using exact features for prediction \n",
    "X1_new = test_data[['Highest market value in eur', 'Season', 'Last Season', 'Attendance']]\n",
    "\n",
    "predicted_mv = model_mv.predict(X1_new)\n",
    "test_data['predicted Market Value'] = predicted_mv\n",
    "predicted_mv_rounded = np.round(predicted_mv).astype(int)\n",
    "predicted_mv_rounded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26839cf-cab4-4fd7-b74b-8df759641de1",
   "metadata": {},
   "source": [
    "# Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fccbe6d-c10d-481b-9854-ca4eba3cadd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = df_scaled_mv\n",
    "\n",
    "# Sample 30 values from 'Market value in eur' column\n",
    "sample_market_values = df_scaled['Market value in eur'].sample(50, random_state=42)\n",
    "pop_mean_market_value = df_scaled['Market value in eur'].mean()\n",
    "\n",
    "# One-sample z-test\n",
    "z_stat, p_value_z = ztest(sample_market_values, value=pop_mean_market_value)\n",
    "print(\"Z-Test for Market Value\")\n",
    "print(\"Z-statistic:\", z_stat)\n",
    "print(\"P-value:\", p_value_z)\n",
    "\n",
    "# T-Test example (sample size > 30 or unknown population variance)\n",
    "# Sample 50 values from 'Assists' column\n",
    "sample_assists = df_scaled['Assists'].sample(28, random_state=42)\n",
    "pop_mean_assists = df_scaled['Assists'].mean()\n",
    "\n",
    "# One-sample t-test\n",
    "t_stat, p_value_t = ttest_1samp(sample_assists, pop_mean_assists)\n",
    "print(\"\\nT-Test for Assists\")\n",
    "print(\"T-statistic:\", t_stat)\n",
    "print(\"P-value:\", p_value_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1035fac1-3e61-4f8a-a2d0-2618240d00a2",
   "metadata": {},
   "source": [
    "# Log Reg model for high / low attend pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d398a6e-82f1-42d7-83e6-c9bfd27bb07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_features_att = final_df.select_dtypes(include='number').columns.tolist()\n",
    "df_att = final_df[possible_features_att]\n",
    "\n",
    "# Create binary attendance category (High/Low) based on median Attendance\n",
    "threshold = df_att['Attendance'].median()\n",
    "bins = [df_att['Attendance'].min() - 1, threshold, df_att['Attendance'].max() + 1]\n",
    "labels = ['Low', 'High']\n",
    "df_att['Attendance_Category_hl'] = pd.cut(df_att['Attendance'], bins=bins, labels=labels)\n",
    "\n",
    "# Map Attendance_Category to numeric for correlation\n",
    "df_att['Attendance_Category_Num'] = df_att['Attendance_Category_hl'].map({'Low': 0, 'High': 1})\n",
    "\n",
    "# Add Attendance_Category_Num to correlation dataframe\n",
    "corr_features = possible_features_att + ['Attendance_Category_Num']\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = df_att[corr_features].corr()\n",
    "\n",
    "# Plotting heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', square=True)\n",
    "plt.title('Correlation Matrix Heatmap for Attendance Category')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6a7901-9e0c-4010-aa92-3aea16ecf2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining features and target\n",
    "features_hl = ['Highest market value in eur', 'Market value in eur']\n",
    "X_att = df_att[features_hl]\n",
    "y_att = df_att['Attendance_Category_hl']\n",
    "\n",
    "# Encoding target labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y_att)\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_scaled_hl = scaler.fit_transform(X_att)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_att, X_test_att, y_train_att, y_test_att = train_test_split(X_scaled_hl, y_encoded, test_size=0.3, random_state=5, stratify=y_encoded)\n",
    "\n",
    "# Train logistic regression model\n",
    "model_att = LogisticRegression()\n",
    "model_att.fit(X_train_att, y_train_att)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_att = model_att.predict(X_test_att)\n",
    "\n",
    "accuracy_att = accuracy_score(y_test_att, y_pred_att)\n",
    "precision_att = precision_score(y_test_att, y_pred_att)\n",
    "recall_att = recall_score(y_test_att, y_pred_att)\n",
    "f1_att = f1_score(y_test_att, y_pred_att)\n",
    "report = classification_report(y_test_att, y_pred_att, target_names=le.classes_)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy_att:.3f}')\n",
    "print(f'Test Precision: {precision_att:.3f}')\n",
    "print(f'Test Recall: {recall_att:.3f}')\n",
    "print(f'Test F1 Score: {f1_att:.3f}')\n",
    "print('Classification Report:\\n', report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a398ecf1-749d-43b9-a277-89a5442dad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f9cf06-4ab2-4ba0-a1fd-f8ec911d724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Get predicted probabilities for the positive class (assuming binary classification)\n",
    "y_score = model_att.predict_proba(X_test_att)[:, 1]\n",
    "\n",
    "# Compute ROC curve and ROC area\n",
    "fpr, tpr, _ = roc_curve(y_test_att, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plotting ROC curve\n",
    "plt.plot(fpr, tpr, color='Purple', label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='Black', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99879950-5313-481b-bca7-50711e01c98b",
   "metadata": {},
   "source": [
    "# K MEANS CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d3bc8c-a094-4f90-a9ab-db3840b309e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clust.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4221ba4-6136-4646-a42c-8ef99d40fbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clust = final_df  \n",
    "features_kmc = ['Goals', 'Assists']\n",
    "\n",
    "# Aggregate by player (mean of numeric features)\n",
    "player_data_kmc = df_clust.groupby('Player Name')[features_kmc].mean()\n",
    "\n",
    "# Scaling data\n",
    "scaler = StandardScaler()\n",
    "player_data_scaled_kmc = scaler.fit_transform(player_data_kmc)\n",
    "\n",
    "# We are Using Elbow method to find optimal k\n",
    "wcss = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(player_data_scaled_kmc)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(1, 11), wcss, marker='o', color='purple')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Distortion')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cea84db-1a87-4e43-bb5e-4f0a20f5b018",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "kmeans = KMeans(n_clusters=k, random_state=7)\n",
    "kmeans.fit(player_data_scaled_kmc)\n",
    "\n",
    "player_data_kmc = player_data_kmc.copy()\n",
    "player_data_kmc['Cluster'] = kmeans.labels_\n",
    "\n",
    "# Inverse transform centroids to original scale to interpret clusters\n",
    "centroids = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "centroid_df = pd.DataFrame(centroids, columns=features_kmc)\n",
    "\n",
    "display_clusters = centroid_df.copy()\n",
    "display_clusters.index = display_clusters.index + 1  # Change index from 0-3 to 1-4\n",
    "\n",
    "descriptions = {\n",
    "    1: 'Moderate goal scorers with few assists',\n",
    "    2: 'Low scorers with low assists, possibly defensive',\n",
    "    3: 'Moderate goal scorers with higher assists, supporting attacking players',\n",
    "    4: 'High goal scorers and moderate assisters, primary attackers/forwards'\n",
    "}\n",
    "\n",
    "display_clusters['Description'] = display_clusters.index.map(descriptions)\n",
    "\n",
    "# Map cluster sizes based on original 0-based cluster labels counts\n",
    "sizes = player_data_kmc['Cluster'].value_counts().sort_index()\n",
    "display_clusters['Size'] = sizes.values\n",
    "\n",
    "# Reorder columns for display\n",
    "cols_order = ['Description'] + features_kmc + ['Size']\n",
    "display_clusters = display_clusters[cols_order]\n",
    "print(\"Cluster centroids (means) with descriptions and size:\")\n",
    "print(display_clusters)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = ['red', 'blue', 'green', 'purple']\n",
    "\n",
    "for cluster in sorted(player_data_kmc['Cluster'].unique()):\n",
    "    cluster_points = player_data_kmc[player_data_kmc['Cluster'] == cluster]\n",
    "    plt.scatter(cluster_points['Goals'], cluster_points['Assists'], \n",
    "                label=f'Cluster {cluster + 1}', s=65, alpha=0.7, c=colors[cluster])\n",
    "\n",
    "plt.xlabel('Goals (mean per player)')\n",
    "plt.ylabel('Assists (mean per player)')\n",
    "plt.title('KMeans Clustering of Players')\n",
    "plt.legend(title='Cluster')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655fb28-6dc7-446c-94f2-dbf848a5ec06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
